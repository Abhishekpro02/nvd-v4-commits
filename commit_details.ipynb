{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def get_most_used_language(owner, repo, api_token):\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/languages\"\n",
    "    \n",
    "    # Randomly select an API token\n",
    "    # api_token = random.choice(api_tokens)\n",
    "    headers = {\"Authorization\": f\"token {api_token}\"}\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        languages = response.json()\n",
    "        if languages:\n",
    "            # Find the most used language by finding the max value in the dictionary\n",
    "            most_used_language = max(languages, key=languages.get)\n",
    "            return most_used_language\n",
    "        else:\n",
    "            return \"Not Available\"\n",
    "    elif response.status_code == 403:\n",
    "        # Handle rate limit errors\n",
    "        return \"Rate limit exceeded. Consider using a different API token.\"\n",
    "    else:\n",
    "        return f\"Failed to retrieve languages for {owner}/{repo}. Status Code: {response.status_code}\"\n",
    "\n",
    "\n",
    "\n",
    "def fetch_commit_details(github_commit_link, api_tokens):\n",
    "    try:\n",
    "        parts = github_commit_link.split('/')\n",
    "        owner = parts[-4]\n",
    "        repo = parts[-3]\n",
    "        commit_sha = parts[-1]\n",
    "        api_url = f\"https://api.github.com/repos/{owner}/{repo}/commits/{commit_sha}\"\n",
    "        project = repo\n",
    "\n",
    "        # Randomly select an API token and rotate the list\n",
    "        api_token = random.choice(api_tokens)\n",
    "        headers = {\"Authorization\": f\"token {api_token}\"}\n",
    "        \n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            commit_details = response.json()\n",
    "            return commit_details, api_url, project, owner, repo, api_token\n",
    "        else:\n",
    "            print(f\"{response.status_code} - Failed to fetch commit details for {github_commit_link}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching commit details for {github_commit_link}: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_csv_with_commit_details(csv_file_path, api_tokens, new_csv_file_path):\n",
    "    # df = pd.read_csv(csv_file_path,nrows=10)\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df[\"language\"] = \"\"\n",
    "    df['api_url'] = ''\n",
    "    df['author'] = ''\n",
    "    df['email'] = ''\n",
    "    df[\"project\"] = \"\"\n",
    "    df[\"commit_id\"] = \"\"\n",
    "    df[\"commit_message\"] = \"\"\n",
    "    df[\"files_changed\"] = \"\"\n",
    "\n",
    "    def process_row(index, row):\n",
    "        result = fetch_commit_details(row['github_commit_link'], api_tokens)\n",
    "        if result:\n",
    "            commit_details, api_url, project, owner, repo, api_token = result\n",
    "            \n",
    "            objects_as_strings = [json.dumps(file) for file in commit_details['files']]\n",
    "            csv_string = '<_**next**_>'.join(objects_as_strings)\n",
    "            \n",
    "            df.at[index, 'language'] = get_most_used_language(owner, repo, api_token)\n",
    "            df.at[index, 'api_url'] = api_url\n",
    "            df.at[index, 'author'] = commit_details['commit']['author']['name']\n",
    "            df.at[index, 'email'] = commit_details['commit']['author']['email']\n",
    "            df.at[index, 'project'] = project\n",
    "            df.at[index, 'commit_id'] = commit_details['sha']\n",
    "            df.at[index, 'commit_message'] = commit_details['commit']['message']\n",
    "            df.at[index, 'files_changed'] = csv_string\n",
    "        else:\n",
    "            return index  # Return the index to drop later if needed\n",
    "        \n",
    "        time.sleep(0.3)  # Add a delay to avoid rate limits\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:  # Adjust the number of workers as needed\n",
    "        futures = {executor.submit(process_row, index, row): index for index, row in df.iterrows()}\n",
    "        drop_indices = []\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    drop_indices.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row: {e}\")\n",
    "\n",
    "    # Drop rows where the commit details could not be fetched\n",
    "    if drop_indices:\n",
    "        df.drop(drop_indices, inplace=True)\n",
    "\n",
    "    df.to_csv(new_csv_file_path, index=False)  # Save to a new CSV file\n",
    "\n",
    "    # Upload the file to MongoDB\n",
    "    print(\"Uploading to MongoDB ðŸš€\")\n",
    "    # upload_csv_to_mongodb(new_csv_file_path)\n",
    "\n",
    "    # Upload the file to AWS S3\n",
    "    print(\"Uploading to AWS S3 ðŸš€\")\n",
    "    \n",
    "    # Send Slack notification\n",
    "    # send_slack_message(\"Data Extraction and Upload Completed Successfully! ðŸŽ‰\")\n",
    "\n",
    "# Example usage:\n",
    "api_tokens = [\n",
    "\n",
    "]\n",
    "\n",
    "csv_file_path = 'all_github_commits_with_vulnerablity_2002-2024.csv'\n",
    "\n",
    "\n",
    "new_csv_file_path =\"all_commit_with_details_2002-24.csv\"\n",
    "\n",
    "\n",
    "update_csv_with_commit_details(csv_file_path, api_tokens, new_csv_file_path)\n",
    "print(\"Data Extraction and Upload Completed Successfully! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
